---
title: "PCA_2"
author: "Vandrade"
date: "2024-08-06"
output: html_document
---


```{r}
library(tidyverse)
library(factoextra)

av <- read.csv("avaliacoes.csv")

```


```{r}

av |> 
  count(marca) |> 
  mutate(pct_marca = prop.table(n)*100,
         marca = fct_reorder(marca, n)) |> 
  ggplot(aes(x = marca, y=pct_marca)) + 
  geom_bar(stat = "identity", fill = 	"#b7ded2") + 
  labs(x = 'Marcas', y = 'Percentual das avaliações') +
  theme_minimal() + 
  coord_flip()
  
```

```{r}

av |> 
  group_by(respondente) |> 
  summarize(marcas_avaliadas = n()) |>
  count(marcas_avaliadas) |> 
  mutate(pct_marcas_avaliadas = prop.table(n)*100) |> 
  ggplot(aes(x = marcas_avaliadas, y = pct_marcas_avaliadas)) + 
  geom_bar(stat = "identity", fill = "#b7ded2") + 
  theme_minimal() + 
  labs(x = 'Número de marcas avaliadas pelo respondentes',
       y = 'Percentual das avaliações')

```


```{r}

quest <- read_csv("questoes.csv")

pca <- av |> 
  select(starts_with('Q')) |> 
  prcomp(scale = TRUE)

# proportion of variance explained

pve <- cumsum((pca$sdev^2) / sum(pca$sdev^2))

```

Kaiser, Henry F. 1961. "A Note on Guttman's Lower Bound for the Number of Common Factors." British Journal of Statistical Psychology 14: 1-2.

An eigenvalue > 1 indicates that PCs account for more variance than accounted by one of the original variables in standardized data. This is commonly used as a cutoff point for which PCs are retained. This holds true only when the data are standardized.

```{r}

pca |> 
  get_eigenvalue() |> 
  filter(eigenvalue >= 1)

```

```{r}

Phi <- pca$rotation

sort( 100*Phi[,1]^2 / sum(Phi[,1]^2), decreasing = TRUE)

```
a contribuição percentual de uma variável é 100 * o quadrado da carga correspodente dividido pela soma dos quadrados das cargas.

a linha tracejada seria o valor de uma contribuição percentual igual para cada variável; ou seja, 100 / número de variáveis

o termo "axes" determina a dimensao (PC) a ser observado
```{r}

sort(100 * Phi[, 1]^2 / sum(Phi[, 1]^2), decreasing = TRUE)


pca |> 
  fviz_contrib("var", axes = 1, sort.val = "asc", fill = '#b7ded2', color = '#b7ded2') +
  labs(x = "", title = 'Contribuições das variáveis para a PC1') + 
  coord_flip()
  
pca |> 
  fviz_contrib("var", axes = 2, sort.val = "asc", fill = '#b7ded2', color = '#b7ded2') +
  labs(x = "", title = 'Contribuições das variáveis para a PC2') + 
  coord_flip()
  

```


```{r}

z <- pca$x[,1:3]

colnames(z) <- sprintf("driver_%d", 1:3)


get_driver <- function(Phi, quest, drv, top) {tibble(numero = rownames(Phi), carga = Phi[, drv]) %>%
        left_join(quest) %>%
        mutate(contribuicao = carga^2 / sum(carga^2)) %>%
        arrange(desc(contribuicao)) %>%
        head(n = top)}


```
os sinais relativos carga x score são importantes! 
abaixo, com os sinais originais, Q28 com escore mais negativo indicaria mais limpeza


```{r}

driver_1 <- get_driver(Phi, quest, drv = 1, top = 6) # Limpeza


```
ajustando os sinais relativos para tornar mais direta a interpretação da PC1
```{r}

Phi[, 1] <- -Phi[, 1]
z[, 1] <- -z[, 1]

(driver_1 <- get_driver(Phi, quest, drv = 1, top = 6)) # Limpeza

(driver_2 <- get_driver(Phi, quest, drv = 2, top = 10)) # Suavidade

(driver_3 <- get_driver(Phi, quest, drv = 3, top = 5)) # Intensidade



```

```{r}

library(ggrepel)

tb <- tibble(marca = av$marca) |> 
    bind_cols(as_tibble(z))
              

tb |> 
  group_by(marca) |> 
  summarise_all(mean) |> 
  gather(key = 'driver', value = 'score_medio', driver_1:driver_3) |> 
  ggplot(aes(x = driver, y = score_medio,
         group = marca, color = marca,
         label = ifelse(driver == "driver_1", marca, ""))) + 
  geom_line(size = 1, alpha = .55) + 
  geom_point(size = 2) + 
  labs(x = "",
       y = "Escore Medio",
       title = "Posicionamento das marcas") + 
  geom_label_repel(direction = "both") + 
  scale_x_discrete(breaks = sprintf("driver_%d", 1:3),
                   labels = c("Limpeza", 
                              "Suavidade",
                              "Intensidade")) + 
  theme(legend.position = "none")

```


